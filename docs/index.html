<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring Project Proposal</h1>
		<div style="text-align: center;">Names: Annabel Ng, George Rickus, Henry Ko, Samarth Jajoo</div>

		<br>
		Link to webpage: <a href="https://g4ce99.github.io/N3CTAR/">g4ce99.github.io/N3CTAR/</a>

		<br>
		Link to GitHub repository: <a href="https://github.com/G4ce99/N3CTAR">github.com/G4ce99/N3CTAR</a>

		<h2>N3CTAR: Neural 3D Cellular Tessellated Automata Rendering</h2>
		For our final project N3CTAR, we will be creating a generalizable framework for rendering dynamic 3D objects in real-time using neural cellular automata. 
		Our implementation will convert an input triangle mesh into a voxel representation and train a convolutional neural network that learns to create/regenerate this voxel representation from minimal/damaged voxel grids. 
		We plan to build on past work by making the process more efficient through approaches like model quantization and directly mapping model outputs to GPU shaders for improved efficiency. 


		<h2>Problem Description</h2>
		<!-- TODO: ADD PROBLEM DESCRIPTION -->
		Neural cellular automata (NCAs) models learn to simulate complex dynamic systems by iteratively updating the state of a grid or lattice based on local rules. This allows them to capture emergent behaviors and patterns that arise from simple interactions between neighboring cells, making them suitable for tasks such as image generation, texture synthesis, and even simulating physical phenomena. However, traditional NCAs often operate on 2D grids, limiting their application to flat images or textures. Most efforts at 3D NCAs have focused on extending the 2D cellular automata framework to  simple 3D shapes like spheres, cubes, or other geometries, but these approaches don't allow for flexibility of dynamically regenerating complex 3D objects that go beyond geometric shapes like seen in this <a href="https://distill.pub/2020/growing-ca/#experiment-3">2D NCA simulation of Growing Neural Cellular Automata</a>. 
		<br><br>

		This problem is relevant because NCAs are useful for studying biological pattern formation and growth patterns, and extending them to a more complex 3D simulation opens up new possibilities for simulating more complex biological processes. It could also allow for cool 3D effects in games and interactive applications, such as destructible environments or dynamic object regeneration. The main challenge of this project lies in efficiently representing, rendering, and regenerating these 3D NCAs while maintaining real-time performance, especially when dealing with complex geometries and dynamic updates, and it'll be interesting to train and integrate the NCA model with GPU rendering techniques to achieve this.
		
		<br><br>
		Our project will tackle:
		<ol>
			<li>Generating voxel representations of non-trivial 3D objects with NCAs, such as animals or complex structures, from a given triangle mesh. This involves converting the mesh into a voxel grid while preserving the object's shape and details and training a neural network to learn the cellular automata update rules for this voxel grid. </li>
			<li>Enabling real-time rendering of these voxel representations while allowing for dynamic updates (i.e. user-controlled destruction and regeneration of the 3D object). </li>
			<li>Improving the efficiency of the rendering process by optimizing model inference and shading directly on the GPU.</li>
		</ol>
	
        <h2>Goals and Deliverables</h2>
		 <ul>
			<li>(1) What We Plan to Deliver</li><br>
			<!-- describe what you believe you must accomplish to have a successful project and achieve the grade you expect (i.e. your baseline plan -->
			We plan to have a framework for rendering dynamic 3D objects in real-time using neural cellular automata. Our baseline plan is that we have can present a cellular automata of a 3D mesh that can be 
			reconstructed when user destroys part of the mesh. This reconstruction process will be handled by a small neural network that we train. Note that this is different from a deterministic reconstruction of a given
			3D object since neural cellular automata reconstructs the missing parts of an object by iterating only on a local part of the object.  <br>
			<br>
			With this goal in mind, some metrics we can record to test the generalizability and performance of our model is to test the following:
			<ul>
				<li>Reconstruction Accuracy(Mean Squared Error): Plot Reconstruction accuracy(MSE) vs. voxel grid size(num of voxels)</li>
				<li>Reconstruction Speed(s): Plot reconstruction speed(s) vs. voxel grid size(num of voxels)</li>
				<li>Robustness to Corrupted Data: Plot Reconstruction accuracy(MSE) vs. Percentage of voxels destroyed(%), for a fixed size voxel grid size</li>
			</ul>
			<br>
			<li>(2) What We Hope to Deliver</li><br>
			We'd like to speed up the reconstruction process by optimizing model inference through
			quantization and parallel execution. We're also hoping to spend time in making the reconstruction fo a damaged mesh look more "organic": for example, adding pink-colored " to the inside of the mesh, which is exposed upon damage to it, and eventually rebuilt and transformed back to "skin".
		 </ul>

        <h2>Schedule</h2>
		
		<h3>Week 1: Voxel Generation and Model Training</h3>
		<h4>VOXEL GENERATION</h4>
		<ul>
			<li>Flood Fill Algorithm: Either implement flood fill on our own to convert a 3D mesh to a voxel grid (by flooding the region outside of the mesh) or use existing python libraries that can do this for us</li>
			<li>Voxel Coloring: Color voxels by casting rays from the camera to random positions in the voxel and use the UV-barycentric interpolation to aggregate the sample colors to generate a single voxel color value (Pytorch3D seems to have what we need for raycasting in this part or we can reimplement this on our own). For non-surface voxels, we can color it with noise that we can convert to colors like pink to represent the internal flesh of say a 3D lizard.</li>
		</ul>
		<h4>MODEL TRAINING</h4>
		<ul>
			<li>Create a scheme for artificially damaging groud truth voxel grid to use in training data alongside single "seed" voxel training to increase model robustness</li>
			<li>We train a small 2 to 3 layer CNN in PyTorch using 3D convolutions to learn the cellular automata update rule from the surrounding 26 voxels + itself (3x3x3 Conv) for a single 3D object</li>
			<li>Expirement with Model Quantization to improve speed down the line and test various architectures to see how small we can make the model while maintaining performance.</li> 
		</ul> 
		
		<h3>Week 2: Voxel Rendering, Shading, and Updates</h3>
		<h4>VOXEL RENDERING</h4>
		<ul>
			<li>Create an efficient strategy for tracking all voxels on/near surface whose existence/color may be changed</li>
			<li>We generate cube mesh instances for every colored voxel on the surface of a given time-step tracking on GPU directly with OpenGL, only rendering those using shader that are not occluded, but tracking the colors of all voxels nonetheless.</li>
		</ul>
		<h4>DYNAMIC VOXEL SHADING</h4>
		<ul>
			<li>Use the TorchLib C++ package to load in our CNN model trained in python and at every timestep, run inference on all surface voxels</li>
			<li>Shade the Cube instances using GLSL with the colors being part of the model output (i.e. last 3 values). We can directly bind this portion of the inference output to the cube's shader for efficiency (keep everything directly on GPU)</li>
		</ul>
		
		<h3>Week 3: User-controlled Voxel Destruction, Voxel Object Regeneration, and Fine-Tuning</h3>
		<h4>USER VOXEL DESTRUCTION / REGENERATION</h4>
		<ul>
			<li>When user clicks with cursor, we cast a ray from cam through the cursor to find intersection coordinates with the voxel object.</li>
			<li>Delete existing cubes in voxel object based on intersection coordinate in a brush style(cylindrical) pattern</li>
			<li>Experiment with other deletion algorithms (i.e. maybe leave some flesh tendrils with a random probability) to make regeneration look more appealing</li>
		</ul>
		<h4>FINE-TUNING</h4>
		<ul>
			<li>Ensure all previous steps are working well</li>
			<li>Further experiment with model architecture and try to make more optimizations / parallelize more</li>
			<li>Experiment with other more realistic voxel coloring schemes</li>
		</ul>

		<h3>Week 4: Last-second Fine-tuning and Presentation/Demo creation</h3>
		<h4>FINE-TUNING (as time permits)</h4>
		<ul>
			<li>Ensure all previous steps are working as well as possible</li>
		</ul>
		<h4>PRESENTATION / DEMO</h4>
		<ul>
			<li>Build the presentation and record videos of any demos</li>
			<li>Record Final video presentation</li>
			<li>Build project website</li>
		</ul>


        <h2>Resources</h2>

		<h4>References</h4>
		 <ul>
			<li><a href="https://distill.pub/2020/growing-ca/#experiment-3">2D Growing Neural Cellular Automata (distill.pub/2020/growing-ca/#experiment-3)</a></li>
			<li><a href="https://github.com/Aadityaza/3d-Growing-neural-cellular-automata">3D Growing Neural Cellular Automata</a></li>
			<li><a href="https://meshnca.github.io/">Mesh Neural Cellular Automata</a></li>
			<li><a href="https://wandb.ai/johnowhitaker/nca/reports/Fun-With-Neural-Cellular-Automata--VmlldzoyMDQ5Mjg0">Fun with Neural Cellular Automata</a></li>
			<li><a href="https://greydanus.github.io/2022/05/24/studying-growth/">Studying Growth with Neural Cellular Automata</a></li>
			<li><a href="https://playgameoflife.com/">Conway's Game of Life</a></li>
			<li><a href="https://arxiv.org/pdf/2103.08737">Growing 3D Artefacts and Functional Machines with Neural Cellular Automata</a></li>
		 </ul>
		
		<h4>GPU Resources</h4>
		 <ul>
			<li>2 x NVIDIA 2080Ti 11GB</li>
			<li>1 x NVIDIA A6000 48GB (only if more compute is necessary)</li>
		 </ul>
		</div>
	</body>
</html>